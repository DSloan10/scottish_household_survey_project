---
title: "R Notebook"
output: html_notebook
---

```{r}
library(tidyverse)
library(janitor)

green_blue_data <- read_csv("data/complete_dist_blue_green.csv") %>% clean_names()
neighbour_rate_data <- read_csv("data/complete_neighbourhood_rating.csv") %>% clean_names()
commun_bel_data <- read_csv("data/complete_community_belonging.csv") %>% clean_names()
```

We are using the following statement from one of the governement's methodology glossaries to guide this exploration into the provided 95% confidence intervals and how we can use these in our analysis:

There are two different ways of using the estimates: Looking backward and looking forward. The following statement and examples refers to looking backward:

"Quite often in Government, the information we receive is simply the estimate and the relevant CIs. We need to be able to use this information as a rule of thumb to assess whether we think there has been a significant change. If the intervals do not overlap then there is a significant difference between two points, but if they do overlap it does not necessarily mean there is no significant difference."

Here, there seems to be 3 rules to exercise to test significance:

1. The difference between a and b is greater than or equal to the sum of the magnitude of the intervals.

2. If the above statement is not true, The difference between a and b is smaller than the larger interval of the two points.

3. If neither 1 or 2 are true, then The difference between a and b is greater than or equal to the square root of the sum of the squares of the two magnitudes (in this case √(32+42) = √(9+16) = 5)

```{r}
#Let's just do a bit of a test on these with the Scotland only figures
scotland_green_blue <-
green_blue_data %>% 
  filter(feature_code == "S92000003")
```

```{r}
scotland_gb_pivot <-
scotland_green_blue %>% 
  pivot_wider(names_from = measurement, values_from = value) %>% 
  clean_names() %>% 
  arrange(date_code)
  
```

```{r}
scotland_gb_pivot_with_intervals <-
scotland_gb_pivot %>% 
  mutate(upper_interval = x95_percent_upper_confidence_limit_percent - percent,
         lower_interval = percent - x95_percent_lower_confidence_limit_percent, 
         combined_interval = upper_interval + lower_interval)
```

```{r}
scot_2013_2019 <-
scotland_gb_pivot_with_intervals %>% 
  filter(distance_to_nearest_green_or_blue_space == "A 5 minute walk or less",
         date_code %in% c(2013, 2019))
```

Now to try and work out if the differences in change amongst certain groups has been significant according to the Scottish Government methodology. Maybe try these one at a time:

1. The difference between a and b is greater than or equal to the sum of the magnitude of the intervals.

```{r}
scot_2013_2019_pivot_wide <-
scot_2013_2019 %>% 
  pivot_wider(names_from = date_code, values_from = x95_percent_upper_confidence_limit_percent:combined_interval)
  
```

```{r}
scot_2013_2019_pivot_wide 
```

```{r}
#Think I could probably write a couple of functions for this, maybe something to look into later.

#So I've made a slight adjustment to this formula whereby because the plus minus figures are not the same, I've just taken the sum of them and then divided by two. Not sure if this is the right thing to do but should be easily changeable if not. 

scot_13_19_signifiers_less_5 <-
scot_2013_2019_pivot_wide %>% 
    mutate(signif_1 = if_else(abs(percent_2013-percent_2019) >= ((combined_interval_2013 + combined_interval_2019)/2), TRUE, FALSE),
           signif_2 = if_else((abs(percent_2013-percent_2019)) < (pmax(combined_interval_2013/2, combined_interval_2019/2)), FALSE, TRUE),
           signif_3 = if_else((abs(percent_2013-percent_2019)) >= (sqrt(((combined_interval_2013/2)^2) + ((combined_interval_2019/2)^2))), TRUE, FALSE)
    )
         

```
Looking at the table above, I think it makes a relatively interesting point in itself. Basically, amongst the groups that are set out here, there has been no significant change in figures from 2013 to 2019. This suggests a fairly static set of phenomenon. **IGNORE THE ABOVE - FORMULA ADJUSTED!!!**

Worth having a go at the entire data set, filtered for only 2013 and 2019 and once again just for the 5-minute walk grouping. We may have to add the last of the 3 rules to the code if any TRUEs come up amongst the second signifiers. 

We'll need to put these bloody codes in again, should really have done this at the start for all the datasets. 
```{r}
local_authority_codes <- read_csv("data/Local_Authority_Districts_Codes.csv") %>% clean_names()
```

```{r}
scot_local_auth_codes <-
local_authority_codes %>% 
  filter(str_detect(lad19cd, "S12")) %>% 
  select(lad19cd, lad19nm) %>% 
  rename(feature_code = lad19cd,
         local_authority = lad19nm)
```

```{r}
gb_with_las_data <-
full_join(green_blue_data, scot_local_auth_codes, "feature_code")

gb_with_las_data <-
gb_with_las_data %>% 
  mutate(local_authority = if_else(feature_code == "S92000003", "Scotland", local_authority))

gb_with_las_data
```


```{r}
gb_2013_2019_las_5_min <-
gb_with_las_data %>% 
  filter(distance_to_nearest_green_or_blue_space == "A 5 minute walk or less",
         date_code %in% c(2013, 2019))
```

```{r}
all_2013_2019_pivot_with_intervals <-
  gb_2013_2019_las_5_min %>%
    pivot_wider(names_from = measurement, values_from = value) %>% 
    clean_names() %>% 
    mutate(upper_interval = x95_percent_upper_confidence_limit_percent - percent,
           lower_interval = percent - x95_percent_lower_confidence_limit_percent, 
           combined_interval = upper_interval + lower_interval) %>% 
    arrange(date_code)
  
```

```{r}
all_2013_2019_pivot_with_intervals
```

```{r}
all_2013_2019_pivot_wide <-
all_2013_2019_pivot_with_intervals %>% 
  pivot_wider(names_from = date_code, values_from = percent:combined_interval)
```

```{r}
all_2013_2019_pivot_wide
```

```{r}
all_2013_2019_pivot_wide %>% 
summarise(across(.fns = ~sum(is.na(.x))))
```

```{r}
#Thinking I should just drop the nas for this part. No way to tell if there has been a significant change if we don't have start and end points.

all_2013_2019_pivot_wide <-
  all_2013_2019_pivot_wide %>% 
  drop_na()
```

```{r}
#This is now accurate

all_13_19_signifiers_less_5 <-
all_2013_2019_pivot_wide %>% 
    mutate(signif_1 = if_else(abs(percent_2013-percent_2019) >= ((combined_interval_2013 + combined_interval_2019)/2), TRUE, FALSE),
           signif_2 = if_else((abs(percent_2013-percent_2019)) < (pmax(combined_interval_2013/2, combined_interval_2019/2)), FALSE, TRUE),
           signif_3 = if_else((abs(percent_2013-percent_2019)) >= (sqrt(((combined_interval_2013/2)^2) + ((combined_interval_2019/2)^2))), TRUE, FALSE)
    )
         
```

Right, so we have managed to get all the formula working for the different looking backward scenarios, which means we can now plot the grou[s that have seen significant change. To acheive this, we might have to do another pivot longer for both datasets. 

First, Scotland-wide:

```{r}
scot_to_add_13_19_sig_less_5 <-
scot_13_19_signifiers_less_5 %>% 
  pivot_longer(c(age, gender, urban_rural_classification, simd_quintiles, type_of_tenure, household_type, ethnicity), names_to = "type", values_to = "class") %>% 
  filter(class != "All")
```

```{r}
extra_scot_to_add_13_19_sig_less_5 <-
scot_13_19_signifiers_less_5 %>% 
    filter(age == "All", 
         gender == "All",
         urban_rural_classification == "All",
         simd_quintiles == "All",
         type_of_tenure == "All",
         household_type == "All",
         ethnicity == "All",
    ) %>% 
  pivot_longer(c(age, gender, urban_rural_classification, simd_quintiles, type_of_tenure, household_type, ethnicity), names_to = "type", values_to = "class") %>%
  slice_head(n = 1) %>% 
  mutate(type = recode(type, age = "All"))

extra_scot_to_add_13_19_sig_less_5
```

```{r}
final_scot_13_19_sig_less_5 <-
bind_rows(scot_to_add_13_19_sig_less_5, extra_scot_to_add_13_19_sig_less_5)
```

```{r}
final_scot_13_19_sig_less_5
```

Now I'll go all the less 5s:


```{r}
all_to_add_13_19_sig_less_5 <-
all_13_19_signifiers_less_5 %>% 
  pivot_longer(c(age, gender, urban_rural_classification, simd_quintiles, type_of_tenure, household_type, ethnicity), names_to = "type", values_to = "class") %>% 
  filter(class != "All")

all_to_add_13_19_sig_less_5
```

```{r}
extra_all_to_add_13_19_sig_less_5 <-
all_13_19_signifiers_less_5 %>%
  filter(age == "All", 
         gender == "All",
         urban_rural_classification == "All",
         simd_quintiles == "All",
         type_of_tenure == "All",
         household_type == "All",
         ethnicity == "All",
    ) %>% 
  pivot_longer(c(age, gender, urban_rural_classification, simd_quintiles, type_of_tenure, household_type, ethnicity), names_to = "type", values_to = "class") %>%
  mutate(type = recode(type, age = "All")) %>% 
  filter(type == "All")
```

```{r}
final_all_13_19_sig_less_5 <-
bind_rows(all_to_add_13_19_sig_less_5 , extra_all_to_add_13_19_sig_less_5)
```

That's done, now we can quickly tag these with significance.

```{r}
final_scot_13_19_sig_less_5 <-
final_scot_13_19_sig_less_5 %>% 
  mutate(sign_change_13_to_19 = if_else(signif_1 | signif_2 | signif_3 == "TRUE", TRUE, FALSE))
```
```{r}
final_all_13_19_sig_less_5 <-
final_all_13_19_sig_less_5 %>% 
  mutate(sign_change_13_to_19 = if_else(signif_1 | signif_2 | signif_3 == "TRUE", TRUE, FALSE))
```

```{r}
final_all_13_19_sig_less_5 %>% 
  filter(sign_change_13_to_19 != TRUE)
```

